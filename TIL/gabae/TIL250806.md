# TIL 250806

## 오늘 한 일
- k6, influxDB, grafana까지 성능 테스트를 위한 설정 완
    - 왜 이걸 써야하는지 조사하고 설정
- api 성능테스트를 위해 load-test 시나리오 짜고 대시보드 커스텀
    - 어떤 메트릭을 넣을지 고민하면서 넣음
- load-test 아직 테스트용으로 분 단위만 돌려봄...ㅠㅠ 오늘 서버 이슈가 있었어서..
- 프론트 요청에 따라 isMicOn을 웹소켓 이벤트에 반영
- Prometheus 설정에 개발 서버 타겟 추가
    

## 오늘의 배운점/고민
- 진행 전, 성능테스트 툴을 비교 분석을 진행
    - 많은 툴 중 K6를 사용한 이유는 “최대 RPS, 메모리 사용량, 정확도 측면”에서 다른 툴에 비해 좋기 때문에 선택
    - Jmeter, ngrinder, Locust도 후보에 있었으나 Jmeter 와 ngrinder는 JVM 위에서 동작하기 때문에 메모리를 많이 사용하고 느리다는 단점이 존재
    - Locust는 python 으로 편하게 작성할 수 있다는 장점이 있으나 최대 rps, 메모리 사용, 정확도 측면에서 k6보다 훨씬 떨어졌기에 제외
    - 또한, 100VU에서 locust는 측정오류가 매우 높기때문에, 즉, 응답시간이 매우 느리게 돌아오기때문에 최대 RPS, 메모리 사용량, 응답시간을 이유로 K6를 선택
    - K6를 통해 안정적인 성능 테스트를 수행할 수 있었지만,측정된 수많은 지표들을 저장하고 분석하는 인프라도 중요
    - 그래서 시계열 데이터 저장에 특화된 InfluxDB, 그리고 이를 시각적으로 분석 가능한 Grafana를 함께 구성

- 메트릭 선택

| 항목                    | 선택 이유                   | 설명 |
|-----------------------|--------------------------|------|
| **Virtual Users**      | 부하 점증 과정 확인          | 시간에 따라 가상 사용자(VU)가 잘 증가하는지, 테스트 설정대로 잘 작동하는지 확인하는 기본 지표 |
| **Requests per Second (RPS)** | 전체 요청 처리량 확인       | 시스템이 초당 몇 개의 요청을 처리했는지 보는 지표. 실제 서비스 대응 성능과 유사 |
| **http_reqs**          | 태그별 요청 수 확인           | 태그별로 어떤 API가 얼마나 많이 호출되었는지 확인하기 |
| **http_req_failed**    | 요청 실패 여부 파악           | 응답 실패(4xx, 5xx) 여부를 확인해서 병목 구간 파악. 특히 대량 부하 시 유용 |
| **http_req_duration**  | 전체 API 응답 시간 확인        | 모든 요청의 응답 시간 평균, 최대, P95 등 → 성능의 종합적 척도 |
| **http_req_blocked**   | 자원 병목 확인 (로컬 한정)      | VU가 요청 보낼 수 없어 대기한 시간 → 로컬 자원(스레드, 커넥션) 부족 여부 확인 |
| **vus_max**            | 설정한 최대 부하 수치 확인      | 500명까지 테스트가 진행됐는지 시각적으로 확인하기 위함 |
| **요약 통계 (duration/blocked)** | 전체 평균/최대/중간값/백분위 확인 | 순간 그래프 외에도 요약 수치로 성능 판단 가능. 특히 max, P95는 병목 파악에 유리 |


테스트는 아래 세 개 할 예정..
Load Test: 현실적 시나리오로 기본 성능 검증
Spike Test: 단기간 요청 폭증 대응 능력
Endurance Test: 장기 운영 안정성

## 내일 할 일
- 시나리오 오늘 쓴 것처럼 하는게 좋은지...한 번 다시 찾아보고 할 예정
- 영우 오빠의 웹소켓 이벤트 추가 반영 예정
